{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "database='roomekbot$offers'\n",
    "user='root'\n",
    "password='Ad4Gw2'\n",
    "sql_query = \"select * from offers\" # where city = 'Wroc≈Çaw' and business_type = 'buy'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    connection = mysql.connector.connect(host=host, database=database, user=user, password=password)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql_query)\n",
    "    records = cursor.fetchall()\n",
    "    \n",
    "    sql_query = \"describe offers\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql_query)\n",
    "    titles = cursor.fetchall()\n",
    "    titles = [x[0] for x in titles]\n",
    "    \n",
    "except Error as e:\n",
    "    print(\"Error reading data from MySQL table\", e)\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(data=records, columns=titles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics - show amount of empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isnull().sum()/len(df)*1000)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace None and Nan with mean value or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "# specify which columns to replace with mean value...\n",
    "# imputer = imputer.fit(df[:, 1:3])\n",
    "# df[:, 1:3] = imputer.transform(df[:, 1:3])\n",
    "\n",
    "# ... and which replace with zero:\n",
    "# df[10:14] = df.fillna(0, inplace=True)\n",
    "\n",
    "# or replace all with zeros:\n",
    "df.fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only valuable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/the-complete-beginners-guide-to-data-cleaning-and-preprocessing-2070b7d4c6d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Matrix of dependent variables:\n",
    "X = df.drop(['price', 'parsed_fields', 'offer_from', 'offer_url', 'offer_name', 'offer_thumbnail_url', 'offer_id', 'offer_text', 'creation_time', 'modification_time', 'street'], axis=1)\n",
    "X.head()\n",
    "# X=X.values\n",
    "\n",
    "# #vector of independent variables:\n",
    "# y = df.loc[:, ['price']]\n",
    "# y=y.values\n",
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print table headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://towardsdatascience.com/the-complete-beginners-guide-to-data-cleaning-and-preprocessing-2070b7d4c6d\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# # Matrix of dependent variables:\n",
    "# X = df.drop(['price', 'parsed_fields', 'offer_from', 'offer_url', 'offer_name', 'offer_thumbnail_url', 'offer_id', 'offer_text', 'creation_time', 'modification_time', 'street'], axis=1)\n",
    "# X.head()\n",
    "# # X=X.values\n",
    "\n",
    "# # #vector of independent variables:\n",
    "# # y = df.loc[:, ['price']]\n",
    "# # y=y.values\n",
    "# # X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels for categorical data - text into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0])\n",
    "\n",
    "# enc = OneHotEncoder(categorical_features = [0])\n",
    "# X = enc.fit_transform(X).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into dependent and intependent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc_X = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# X_test = sc_X.transform(X_test)\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
